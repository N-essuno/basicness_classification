{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Binary classification (basic/advanced) for synsets\n",
    "\n",
    "We use the already classified synsets from data folder as training/test set.\n",
    "For each synset provided there are one or more relevant words that belongs to the synset. And there is the label (basic/advanced) for the synset.\n",
    "\n",
    "We then consider as features for classification the following:\n",
    "1. The depth of the synset in the WordNet hierarchy\n",
    "2. The pronunciation complexity of the first word **in the dataset**\n",
    "3. The length of the first word **in the dataset**\n",
    "4. The synset classification to concrete or abstract concept\n",
    "\n",
    "Given a new synset we want to classify we then get its features by:\n",
    "1. Getting the depth of the sysnet in the WordNet hierarchy\n",
    "2. Getting the pronunciation complexity of the first (most frequently used) word **in the synset**\n",
    "3. Getting the length of the first (most frequently used) word **in the synset**\n",
    "4. Predicting the synset classification to concrete or abstract concept\n",
    "\n",
    "After defining data we train a binary classifier to predict the label (basic/advanced) of the synset.\n",
    "Since we have a small dataset we use a simple logistic regression classifier trained using 5-fold cross validation.\n",
    "\n",
    "Steps:\n",
    "1. Load and format the JSON dataset (synsets, word(s), labels, definitions) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee2a4e9d05762d02"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import openpyxl # install it as it is required by pandas to read excel files\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus.reader import Synset\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import cmudict\n",
    "\n",
    "import spacy\n",
    "import joblib\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "# # download the CMU Pronouncing Dictionary\n",
    "# nltk.download('cmudict')\n",
    "# spacy.cli.download(\"en_core_web_md\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:05:38.492045Z",
     "start_time": "2024-04-16T09:05:29.210047700Z"
    }
   },
   "id": "1bd01b4e9d9962d4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load and format the JSON dataset (synsets, word(s), labels, definitions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6466c50de33d51bf"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open('data/1.json') as f:\n",
    "    data = json.load(f)\n",
    "    dataset = data['dataset']\n",
    "    labels = data['answers']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:05:38.523044800Z",
     "start_time": "2024-04-16T09:05:38.492045Z"
    }
   },
   "id": "6504e45c9fc1ff6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get Synset from string of the form \"Synset('word.pos.n')\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6226de7c56eca0db"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_synset_from_string(s: str) -> Synset:\n",
    "    # find first ' and last '\n",
    "    start = s.find('\\'')\n",
    "    end = s.rfind('\\'')\n",
    "    synset_name = s[start + 1:end]\n",
    "    return wn.synset(synset_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:05:38.538044900Z",
     "start_time": "2024-04-16T09:05:38.523044800Z"
    }
   },
   "id": "d47500d668011346"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate pronunce complexity based on number of phonemes\n",
    "If word not found in dictionary return 50, indicating high complexity (max complexity is around 25 in this dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c931e622e1aeaf0d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "pronunce_dict = cmudict.dict()\n",
    "\n",
    "def calculate_pronunce_complexity(sentence: str) -> int:\n",
    "    sentence = sentence.split()\n",
    "    complexity = 0\n",
    "    for word in sentence:\n",
    "        if word.lower() in pronunce_dict:\n",
    "            phonemes = pronunce_dict[word.lower()][0]  # get phonetic representation\n",
    "            complexity += len(phonemes)  # complexity based on number of phonemes\n",
    "        else: # TODO check if returning high complexity if one word not found is better. Maybe\n",
    "            return 50\n",
    "    \n",
    "    if complexity == 0: # if word not found in dictionary return high complexity\n",
    "        return 50\n",
    "    return complexity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:05:39.901610Z",
     "start_time": "2024-04-16T09:05:38.544046700Z"
    }
   },
   "id": "f4e1feb1b71871ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select synset and word(s) from dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "316f22dd3df6bda8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# get classifier with joblib\n",
    "concrete_abstract_cls = joblib.load('trained_models/concrete_abstract_classifier.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:05:39.916607900Z",
     "start_time": "2024-04-16T09:05:39.901610Z"
    }
   },
   "id": "96d9c7c43e15cee7"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# dataframe containing synset, word(s), definition, label\n",
    "cols = ['synset', 'words', 'synset_depth', 'pronunce_complexity', 'first_word_length', 'abstract', 'label', 'definition']\n",
    "dataset_df: DataFrame = pd.DataFrame(columns=cols)\n",
    "\n",
    "splitted_list: List[List[str]] = []\n",
    "label_index = 0\n",
    "for row in dataset:\n",
    "    row_list = []\n",
    "    temp_split = row.split(':')\n",
    "    for elem in temp_split:\n",
    "        splitted = elem.split('|')\n",
    "        row_list.extend([x for x in splitted])\n",
    "    \n",
    "    # get synset\n",
    "    synset = get_synset_from_string(row_list[0])\n",
    "    # get words\n",
    "    words = row_list[1]\n",
    "    words = words.split(',')\n",
    "    words = [word.strip() for word in words]\n",
    "    # take only first word for now, it should be the most frequently used\n",
    "    first_word = words[0]\n",
    "    words = \",\".join(words)\n",
    "    # get synset depth\n",
    "    synset_depth = synset.max_depth()\n",
    "    # get pronunce complexity\n",
    "    pronunce = calculate_pronunce_complexity(first_word)\n",
    "    # get first word length\n",
    "    first_word_length = len(first_word)\n",
    "    # get concreteness\n",
    "    word_vector = list(nlp(first_word))[0].vector\n",
    "    is_abstract = concrete_abstract_cls.predict([word_vector])[0]\n",
    "    # get label\n",
    "    label = labels[label_index]\n",
    "    # get definition\n",
    "    definition = row_list[3]\n",
    "    # add row to dataframe\n",
    "    new_row = [[synset, first_word, synset_depth, pronunce, first_word_length, is_abstract, label, definition]]\n",
    "    dataset_df = pd.concat(\n",
    "        [dataset_df, pd.DataFrame(new_row, columns=cols)], \n",
    "        ignore_index=True)\n",
    "    label_index += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:05:47.945159900Z",
     "start_time": "2024-04-16T09:05:39.918608700Z"
    }
   },
   "id": "1bd456c7d41782ce"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        synset                       words  \\\n0                           Synset('war.n.01')                         war   \n1                       Synset('fiefdom.n.01')                     fiefdom   \n2                           Synset('bed.n.03')                         bed   \n3    Synset('return_on_invested_capital.n.01')  return on invested capital   \n4                       Synset('texture.n.02')                     texture   \n..                                         ...                         ...   \n499                     Synset('reading.n.03')                     reading   \n500           Synset('sanctimoniousness.n.01')           sanctimoniousness   \n501                  Synset('chalcedony.n.01')                  chalcedony   \n502                    Synset('stopcock.n.01')                    stopcock   \n503                  Synset('backpacker.n.01')                  backpacker   \n\n    synset_depth pronunce_complexity first_word_length abstract     label  \\\n0              7                   3                 3        1     basic   \n1              6                   6                 7        1  advanced   \n2              5                   3                 3        0     basic   \n3              6                  22                26        1  advanced   \n4              9                   6                 7        1     basic   \n..           ...                 ...               ...      ...       ...   \n499            6                   5                 7        1     basic   \n500           10                  50                17        1  advanced   \n501            8                   9                10        0  advanced   \n502           11                  50                 8        1  advanced   \n503           10                  50                10        0     basic   \n\n                                            definition  \n0        the waging of armed conflict against an enemy  \n1               the domain controlled by a feudal lord  \n2     a depression forming the ground under a body ...  \n3     (corporate finance) the amount, expressed as ...  \n4                   the essential quality of something  \n..                                                 ...  \n499   a datum about some physical state that is pre...  \n500         the quality of being hypocritically devout  \n501   a milky or greyish translucent to transparent...  \n502   faucet consisting of a rotating device for re...  \n503                       a hiker who wears a backpack  \n\n[504 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>synset</th>\n      <th>words</th>\n      <th>synset_depth</th>\n      <th>pronunce_complexity</th>\n      <th>first_word_length</th>\n      <th>abstract</th>\n      <th>label</th>\n      <th>definition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Synset('war.n.01')</td>\n      <td>war</td>\n      <td>7</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>basic</td>\n      <td>the waging of armed conflict against an enemy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Synset('fiefdom.n.01')</td>\n      <td>fiefdom</td>\n      <td>6</td>\n      <td>6</td>\n      <td>7</td>\n      <td>1</td>\n      <td>advanced</td>\n      <td>the domain controlled by a feudal lord</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Synset('bed.n.03')</td>\n      <td>bed</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>basic</td>\n      <td>a depression forming the ground under a body ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Synset('return_on_invested_capital.n.01')</td>\n      <td>return on invested capital</td>\n      <td>6</td>\n      <td>22</td>\n      <td>26</td>\n      <td>1</td>\n      <td>advanced</td>\n      <td>(corporate finance) the amount, expressed as ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Synset('texture.n.02')</td>\n      <td>texture</td>\n      <td>9</td>\n      <td>6</td>\n      <td>7</td>\n      <td>1</td>\n      <td>basic</td>\n      <td>the essential quality of something</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>Synset('reading.n.03')</td>\n      <td>reading</td>\n      <td>6</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1</td>\n      <td>basic</td>\n      <td>a datum about some physical state that is pre...</td>\n    </tr>\n    <tr>\n      <th>500</th>\n      <td>Synset('sanctimoniousness.n.01')</td>\n      <td>sanctimoniousness</td>\n      <td>10</td>\n      <td>50</td>\n      <td>17</td>\n      <td>1</td>\n      <td>advanced</td>\n      <td>the quality of being hypocritically devout</td>\n    </tr>\n    <tr>\n      <th>501</th>\n      <td>Synset('chalcedony.n.01')</td>\n      <td>chalcedony</td>\n      <td>8</td>\n      <td>9</td>\n      <td>10</td>\n      <td>0</td>\n      <td>advanced</td>\n      <td>a milky or greyish translucent to transparent...</td>\n    </tr>\n    <tr>\n      <th>502</th>\n      <td>Synset('stopcock.n.01')</td>\n      <td>stopcock</td>\n      <td>11</td>\n      <td>50</td>\n      <td>8</td>\n      <td>1</td>\n      <td>advanced</td>\n      <td>faucet consisting of a rotating device for re...</td>\n    </tr>\n    <tr>\n      <th>503</th>\n      <td>Synset('backpacker.n.01')</td>\n      <td>backpacker</td>\n      <td>10</td>\n      <td>50</td>\n      <td>10</td>\n      <td>0</td>\n      <td>basic</td>\n      <td>a hiker who wears a backpack</td>\n    </tr>\n  </tbody>\n</table>\n<p>504 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head(600)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:05:47.999158700Z",
     "start_time": "2024-04-16T09:05:47.945159900Z"
    }
   },
   "id": "36b8663e39c572e1"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abstract advanced words: 134\n",
      "Number of concrete basic words: 117\n"
     ]
    }
   ],
   "source": [
    "# count number of abstract advanced words and concrete basic words\n",
    "abstract_advanced_count = dataset_df[(dataset_df['abstract'] == 1) & (dataset_df['label'] == \"advanced\")].shape[0]\n",
    "concrete_basic_count = dataset_df[(dataset_df['abstract'] == 0) & (dataset_df['label'] == \"basic\")].shape[0]\n",
    "\n",
    "print(f\"Number of abstract advanced words: {abstract_advanced_count}\")\n",
    "print(f\"Number of concrete basic words: {concrete_basic_count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:05:48.127670200Z",
     "start_time": "2024-04-16T09:05:47.982159500Z"
    }
   },
   "id": "1762a93cd61456b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Measure correlation between features and label (basic/advanced)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5a946d04d3a9a88"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def chi_square_test(feature, label):\n",
    "    contingency_table = pd.crosstab(feature, label)\n",
    "    chi2, p_val, _, _ = chi2_contingency(contingency_table)\n",
    "    return chi2, p_val"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18a7f60d5b2c1a68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chi_square_results = {}\n",
    "for col in dataset_df.columns:\n",
    "    if col not in ['synset', 'words', 'label', 'definition']:\n",
    "        continue\n",
    "    pearson_corr = dataset_df[col].corr(dataset_df['label'])\n",
    "    spearman_corr = dataset_df[col].corr(dataset_df['label'], 'spearman')\n",
    "    chi2, p_val = chi_square_test(dataset_df[col], dataset_df['label'])\n",
    "    chi_square_results[col] = {'Chi-square': chi2, 'p-value': p_val}\n",
    "    print(f\"Pearson correlation between {col} and label: {pearson_corr}\")\n",
    "    print(f\"Spearman correlation between {col} and label: {spearman_corr}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79a435a25935d2cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8d48f73dfe2c21c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
