{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Load words with concreteness score from xls file, train a classifier to classify words as concrete or abstract, save the classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad96ced9fc4438b"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57a5d9a6bbd6699",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T08:56:57.564329900Z",
     "start_time": "2024-04-16T08:56:56.146775100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# spacy.cli.download(\"en_core_web_md\")\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# TODO tune concreteness threshold\n",
    "concreteness_df = pd.read_excel(\"data/brysbaert_concreteness_ratings.xlsx\", na_filter=False)\n",
    "# extract list of words with concreteness >= 3 and < 3\n",
    "concrete_words = concreteness_df.query('conc_score >= 3')['word'].tolist()  # words with concreteness >= 3\n",
    "abstract_words = concreteness_df.query('conc_score < 3')['word'].tolist()  # words with concreteness < 3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T08:23:50.304245300Z",
     "start_time": "2024-04-16T08:23:46.375425900Z"
    }
   },
   "id": "225e196be864a6ef"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18776\n",
      "['accumulate', 'add', 'aerially', 'ahead', 'aiming', 'airless', 'alternation', 'anaphylactic', 'anatomically', 'annotate']\n",
      "\n",
      "21178\n",
      "['eh', 'essentialness', 'although', 'spirituality', 'would', 'spiritually', 'whatsoever', 'conceptualistic', 'conventionalism', 'belief']\n"
     ]
    }
   ],
   "source": [
    "print(len(concrete_words))\n",
    "print(concrete_words[:10])\n",
    "print()\n",
    "print(len(abstract_words))\n",
    "print(abstract_words[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T08:23:50.828320600Z",
     "start_time": "2024-04-16T08:23:50.800304700Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "classes = ['concrete', 'abstract']\n",
    "train_set = []\n",
    "train_set.append(concrete_words)\n",
    "train_set.append(abstract_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T08:23:51.855197600Z",
     "start_time": "2024-04-16T08:23:51.844202900Z"
    }
   },
   "id": "f64c50482e1361b"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "# get word vectors list\n",
    "X = np.array([])\n",
    "index = 0\n",
    "for part in train_set:\n",
    "    for word in part:\n",
    "        X.append(nlp(word)[0].vector)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T08:51:19.410243100Z",
     "start_time": "2024-04-16T08:48:27.841019100Z"
    }
   },
   "id": "d4a534c8fe6ed123"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m X \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      3\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m part \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtrain_set\u001B[49m:\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m part:\n\u001B[0;32m      6\u001B[0m         X\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mlist\u001B[39m(nlp(word))[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mvector)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "# get labels\n",
    "y = [label for label, part in enumerate(train_set) for _ in part]\n",
    "classifier = LogisticRegression(C=0.1, class_weight='balanced').fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-16T08:23:12.663099500Z"
    }
   },
   "id": "40ecc9c6fe434588"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "['trained_models/concrete_abstract_classifier.joblib']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save classifier\n",
    "joblib.dump(classifier, \"trained_models/concrete_abstract_classifier.joblib\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T15:06:57.803730900Z",
     "start_time": "2024-04-15T15:06:57.657374Z"
    }
   },
   "id": "289a2d38fd4e8bbc"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# load classifier\n",
    "classifier = joblib.load(\"trained_models/concrete_abstract_classifier.joblib\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T15:06:57.807729400Z",
     "start_time": "2024-04-15T15:06:57.695687100Z"
    }
   },
   "id": "7a3b08270fb04f2b"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "war -> 1 - abstract\n",
      "fiefdom -> 1 - abstract\n",
      "bed -> 0 - concrete\n",
      "return_on_invested_capital -> 1 - abstract\n",
      "texture -> 1 - abstract\n",
      "news -> 0 - concrete\n",
      "look -> 0 - concrete\n"
     ]
    }
   ],
   "source": [
    "synsets = ['war.n.01', 'fiefdom.n.01', 'bed.n.03', 'return_on_invested_capital.n.01', 'texture.n.02', 'news.n.01',\n",
    "           'look.n.02']\n",
    "\n",
    "for synset_str in synsets:\n",
    "    synset = wn.synset(synset_str)\n",
    "    synset_name = synset.lemma_names()[0]\n",
    "    synset_vector = list(nlp(synset_name))[0].vector\n",
    "    synset_class = classifier.predict([synset_vector])[0]\n",
    "    # print classification\n",
    "    print(f'{synset_name} -> {synset_class} - {classes[synset_class]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T15:06:57.895680Z",
     "start_time": "2024-04-15T15:06:57.743689200Z"
    }
   },
   "id": "acbb37d7f68c49e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression version. Predicting concreteness score of a word."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98b8c7d266c6c756"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "new_y = concreteness_df['conc_score']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T08:51:29.306211800Z",
     "start_time": "2024-04-16T08:51:29.277737900Z"
    }
   },
   "id": "d53f519a9986332"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.9317894584297259\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, new_y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T08:51:30.647161400Z",
     "start_time": "2024-04-16T08:51:29.959585900Z"
    }
   },
   "id": "4e2a2b8d1a8e7f99"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39954\n",
      "31963\n"
     ]
    }
   ],
   "source": [
    "#print training set\n",
    "print(len(X))\n",
    "print(len(X_train))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T08:31:45.492146Z",
     "start_time": "2024-04-16T08:31:45.462150400Z"
    }
   },
   "id": "912bcd12a43d8f3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gianl\\Desktop\\UniTo\\tln\\dicaro\\basicness_classification\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.763e+00, tolerance: 3.008e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "alphas = np.logspace(-5, 1, 60)\n",
    "enet = linear_model.ElasticNet(l1_ratio=0.7, max_iter=10000)\n",
    "train_errors = list()\n",
    "test_errors = list()\n",
    "for alpha in alphas:\n",
    "    enet.set_params(alpha=alpha)\n",
    "    enet.fit(X_train, y_train)\n",
    "    train_errors.append(enet.score(X_train, y_train))\n",
    "    test_errors.append(enet.score(X_test, y_test))\n",
    "\n",
    "i_alpha_optim = np.argmax(test_errors)\n",
    "alpha_optim = alphas[i_alpha_optim]\n",
    "print(\"Optimal regularization parameter : %s\" % alpha_optim)\n",
    "\n",
    "# Estimate the coef_ on full data with optimal regularization parameter\n",
    "enet.set_params(alpha=alpha_optim)\n",
    "coef_ = enet.fit(X, new_y).coef_"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-16T08:57:02.174261100Z"
    }
   },
   "id": "ffd9c0de8d2b3aa8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b939a54c46fdc234"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
